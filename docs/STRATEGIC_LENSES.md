# Strategic Lenses

20 ideation agents. Each sees the product through one lens. No synthesis, no conclusions — just forcing questions.

Run any lens against a feature idea, a roadmap decision, or a stuck moment. The lens doesn't answer — it interrogates.

---

## 1. Moat Auditor

**Starts from:** "If models get 10× better, do we still win?"

**Forces you to answer:**
- What do we have that can't be generated?
- What data only exists because users did something here?
- If a CS student rebuilds this in a weekend, what's left?
- What gets more valuable the longer it runs?
- What requires trust that takes years to build?
- What compounds vs. what's static?

**Red flags it catches:**
- "Our moat is great UX" (AI generates UX)
- "Our moat is features" (features are copyable)
- "Our moat is first-mover" (fast followers exist)

**Use when:** Evaluating whether a feature builds durable advantage or just temporary differentiation.

---

## 2. Wedge Designer

**Starts from:** Find the first painful moment with urgency + authority.

**Forces you to answer:**
- Who wakes up today with this problem?
- Why must they solve it *today*, not next week?
- Do they have authority to adopt a solution, or do they need permission?
- What's the "must use today" entry point?
- What existing behavior does this replace?
- Is the pain acute (one moment) or chronic (ongoing)?
- Can they feel relief in the first session?

**Red flags it catches:**
- "Everyone would benefit from this" (no urgency)
- "It's better than what exists" (not painful enough to switch)
- "Once they try it, they'll love it" (requires behavior change)

**Use when:** Choosing where to focus, designing onboarding, evaluating go-to-market.

---

## 3. Distribution Engineer

**Starts from:** Bake acquisition into the workflow — not bolted on.

**Forces you to answer:**
- Does using the product create artifacts that spread?
- Do users *need* to share something to get value?
- What leaves the product and enters the world?
- Who sees HIVE without being a HIVE user?
- What would a user share even if we didn't ask them to?
- Where does the workflow naturally touch non-users?
- What's the "exhaust" of normal usage?

**Red flags it catches:**
- "We'll add share buttons" (nobody uses share buttons)
- "We'll do referral bonuses" (incentivized sharing feels gross)
- "Word of mouth will spread it" (hope is not a strategy)

**Use when:** Designing features, evaluating virality, planning growth without paid acquisition.

---

## 4. Incumbent Failure Analyst

**Starts from:** Why do existing tools structurally fail here?

**Forces you to answer:**
- What would [incumbent] have to change about their core product to compete?
- Is that change compatible with their business model?
- Is that change compatible with their existing users?
- What can't they do without rebuilding from scratch?
- What would their investors/board reject?
- What would their core users hate?
- Why haven't they already done this?

**Red flags it catches:**
- "We're just better" (incumbents can improve)
- "They're too slow" (they can speed up)
- "They don't care about this market" (they might start)

**Use when:** Competitive analysis, positioning, evaluating defensibility.

---

## 5. Data Flywheel Builder

**Starts from:** What data exists only because the product exists?

**Forces you to answer:**
- What do we know that no one else can know?
- What gets more accurate with more usage?
- What patterns emerge from aggregate behavior?
- What would be lost if users exported everything and left?
- What predictions can we make that improve over time?
- What do users teach us by using the product?
- What's the "proprietary corpus"?

**Red flags it catches:**
- "We have user data" (everyone has user data)
- "We know their preferences" (preferences are easily re-collected)
- "We have their content" (content is portable)

**Use when:** Evaluating data strategy, designing features that generate valuable signals, moat assessment.

---

## 6. Workflow Lock-In Architect

**Starts from:** Design processes that become painful to leave.

**Forces you to answer:**
- What state accumulates over time?
- What would break if they switched platforms tomorrow?
- What organizational muscle memory forms around this?
- What approvals, audit trails, or history would be lost?
- What templates, workflows, or automations would need rebuilding?
- What institutional knowledge lives here?
- How does switching cost increase with tenure?

**Red flags it catches:**
- "They'll stay because they like it" (affection isn't lock-in)
- "Switching is inconvenient" (inconvenience is weak lock-in)
- "Their data is here" (data is exportable)

**Use when:** Designing for retention, evaluating stickiness, planning long-term defensibility.

---

## 7. Risk & Liability Strategist

**Starts from:** Turn "errors are expensive" into product value.

**Forces you to answer:**
- What goes wrong when this process fails?
- Who pays when it fails? (money, reputation, legal)
- What proof would they need that it didn't fail?
- What documentation would protect them?
- What audit trail would they wish they had?
- What evidence would a lawyer, auditor, or regulator want?
- How can the product be the source of truth?

**Red flags it catches:**
- "Users don't care about compliance" (until they're sued)
- "That's an edge case" (edge cases create liability)
- "We're not a compliance tool" (every tool can reduce risk)

**Use when:** Designing for regulated industries, enterprise sales, anywhere mistakes are costly.

---

## 8. Regulation Leverage Planner

**Starts from:** Use compliance/standards as the barrier.

**Forces you to answer:**
- What regulations apply to this domain?
- What evidence do regulators require?
- What certifications matter to buyers?
- What would an audit require?
- How can compliance become a feature, not a burden?
- What can't competitors do without the same compliance investment?
- How do regulations change the build-vs-buy decision?

**Red flags it catches:**
- "Compliance is a cost center" (compliance can be a moat)
- "We'll deal with regulations later" (retroactive compliance is expensive)
- "Small players don't need to comply" (until they do)

**Use when:** Entering regulated markets, selling to enterprises, evaluating barriers to entry.

---

## 9. "Time Collapse" Designer

**Starts from:** Target repetitive cognitive steps — replace with auto-drafts + human signoff.

**Forces you to answer:**
- What does the user do repeatedly that feels like work?
- What requires thinking but has predictable patterns?
- What could be pre-filled and reviewed instead of created from scratch?
- What's the "I do this every week" task?
- What decisions are the same 80% of the time?
- Where is a human acting as a slow computer?
- What would they celebrate never doing again?

**Red flags it catches:**
- "Users want control" (they want outcomes, not control)
- "It's too complex to automate" (complexity often has patterns)
- "They'll feel replaced" (they'll feel relieved)

**Use when:** Designing automation, finding AI/ML opportunities, improving efficiency.

---

## 10. Edge-Case Monetizer

**Starts from:** Turn rare-but-costly exceptions into premium modules.

**Forces you to answer:**
- What happens infrequently but hurts badly when it does?
- What do power users need that casual users don't?
- What 5% of use cases require 50% of the complexity?
- What would someone pay extra to handle smoothly?
- What's the "when this breaks, it really breaks" scenario?
- What's currently handled manually because it's rare?
- What would enterprise/pro users pay for that others wouldn't?

**Red flags it catches:**
- "We should handle every case in the free tier" (complexity bloat)
- "Edge cases don't matter" (they matter to someone who'll pay)
- "Premium means more of the same" (premium means different problems)

**Use when:** Pricing, packaging, deciding what's free vs. paid.

---

## 11. Persona Purist

**Starts from:** Keep one buyer/operator persona — kill multi-persona creep.

**Forces you to answer:**
- Who is the ONE person this is for?
- What do they care about that others don't?
- What would we build differently if we only served them?
- What features exist because we're trying to please multiple personas?
- Who do we say no to?
- What's the adjacent persona we must resist?
- If we had to pick one user to make ecstatic, who?

**Red flags it catches:**
- "It's for everyone" (it's for no one)
- "Different user types" (persona creep)
- "We can serve both" (you serve neither well)

**Use when:** Prioritizing features, evaluating scope creep, focusing the product.

---

## 12. Pricing & Packaging Schemer

**Starts from:** Map features to willingness-to-pay — create upgrade pressure.

**Forces you to answer:**
- What would someone pay for that they can't get for free?
- What limit would they hit that makes them want more?
- What's the natural "aha, I need the paid version" moment?
- What's free that should stay free forever (acquisition)?
- What's the value metric that scales with their success?
- Where is the line between "taste" and "full meal"?
- What makes the free tier feel complete but limited?

**Red flags it catches:**
- "The free tier has everything" (no upgrade pressure)
- "We'll figure out pricing later" (pricing shapes the product)
- "Users will pay because they love it" (love doesn't open wallets)

**Use when:** Designing tiers, planning monetization, evaluating freemium strategy.

---

## 13. Ops Automator

**Starts from:** Ideate back-office workflows that should run without humans.

**Forces you to answer:**
- What do we do manually that could be automated?
- What breaks when we're not watching?
- What scales poorly with users?
- What's the "someone should check this" task?
- What cleanup never happens because no one owns it?
- What reports do we generate by hand?
- What would run better on a schedule?

**Red flags it catches:**
- "We'll handle it manually for now" (manual doesn't scale)
- "It only happens occasionally" (occasional still needs handling)
- "Someone will notice" (no one notices until it's broken)

**Use when:** Scaling operations, reducing toil, planning infrastructure.

---

## 14. Market Map Cartographer

**Starts from:** Identify adjacent jobs-to-be-done that reuse the same core.

**Forces you to answer:**
- What else do our users need that we're positioned to provide?
- What capabilities do we already have that solve other problems?
- What's the natural "while you're here" expansion?
- What would require minimal new infrastructure?
- What adjacent problem has the same buyer?
- What's the "we're already trusted for X, why not Y"?
- What markets are one feature away?

**Red flags it catches:**
- "We should stay focused" (focus can become tunnel vision)
- "That's a different product" (it might be the same product for different jobs)
- "We don't want to be a platform" (you might already be one)

**Use when:** Planning expansion, evaluating adjacent opportunities, thinking about platform potential.

---

## 15. Experiment Designer

**Starts from:** Low-cost tests that validate demand without behavior-change fantasies.

**Forces you to answer:**
- What's the cheapest way to learn if this is real?
- What signal would convince us to go harder?
- What signal would convince us to stop?
- What can we test without building anything?
- What existing behavior can we observe?
- What's the smallest version that tests the core hypothesis?
- What are we assuming that we could validate this week?

**Red flags it catches:**
- "We need to build it to test it" (you can test without building)
- "Let's see if users like it" (vague success criteria)
- "If we build it, they'll come" (hope is not validation)

**Use when:** Before building anything, when uncertain about demand, before large investments.

---

## 16. Partnership Hacker

**Starts from:** Find already-trusted gatekeepers to bundle with.

**Forces you to answer:**
- Who does our user already trust?
- Who has the audience we want?
- What's the mutual value exchange?
- Who benefits from our success?
- What would make a partner say "yes" immediately?
- Who's already doing the hard work of aggregating our users?
- What integration would make us indispensable to a partner?

**Red flags it catches:**
- "We'll grow organically" (organic is slow)
- "Partnerships are a distraction" (partnerships are leverage)
- "We don't need anyone else" (distribution is hard alone)

**Use when:** Planning go-to-market, accelerating growth, finding distribution leverage.

---

## 17. Narrative & Positioning Writer

**Starts from:** Turn what the product does into a crisp promise — no jargon, no "AI magic."

**Forces you to answer:**
- What would a user say to a friend in one sentence?
- What's the before/after transformation?
- What pain disappears?
- What capability appears?
- What's the verb? (not "platform for" — what do you DO?)
- What's the unexpected combination that makes this new?
- What would make someone say "finally"?

**Red flags it catches:**
- "It's a platform for..." (platform is not a promise)
- "AI-powered..." (AI is an implementation detail)
- "All-in-one..." (everything for everyone is nothing for anyone)

**Use when:** Writing landing pages, pitching, clarifying what you're actually building.

---

## 18. Competitive Response Planner

**Starts from:** Assume fast followers — ideate what they can't copy without your data/workflow.

**Forces you to answer:**
- If a competitor saw our product today, what could they build in 3 months?
- What would take them 3 years?
- What can't be copied without our users?
- What can't be copied without our history?
- What would they have to change about their core product?
- What advantages do we have that grow with time?
- What's our response if [specific competitor] enters tomorrow?

**Red flags it catches:**
- "We'll stay ahead on features" (features are copyable)
- "Our brand will protect us" (brand is slow to build, fast to lose)
- "They won't notice us" (they will)

**Use when:** Strategic planning, evaluating defensibility, anticipating competition.

---

## 19. Second-Order Effects Skeptic

**Starts from:** Ask "what breaks when this scales?" — anticipate abuse, gaming, perverse incentives.

**Forces you to answer:**
- What happens when 10× more people use this?
- What happens when bad actors discover this?
- What happens when people optimize for the metric?
- What unintended behavior does this incentivize?
- What's the worst case if someone games this?
- What externality do we create?
- What would make us regret building this?

**Red flags it catches:**
- "Users will use it as intended" (they won't)
- "We'll deal with abuse when it happens" (you'll be overwhelmed)
- "This can only be used for good" (everything can be misused)

**Use when:** Designing incentives, planning for scale, evaluating risk.

---

## 20. Roadmap Synthesizer

**Starts from:** Thread ideation back into the spec stack.

**Forces you to answer:**
- What contracts/schemas need to change?
- What state transitions are implied?
- What permissions are required?
- What telemetry would validate this worked?
- What dependencies exist?
- What's the minimum viable version?
- What sequence makes implementation tractable?

**Red flags it catches:**
- "We'll figure out the details later" (details are where ideas die)
- "It's just a small change" (small changes have large implications)
- "The backend can handle it" (the backend probably can't)

**Use when:** Moving from idea to plan, validating feasibility, scoping work.

---

## How to Use These Lenses

**For feature ideation:**
Run the idea through lenses 2 (wedge), 3 (distribution), 5 (data flywheel), 9 (time collapse), 11 (persona). Does it survive all five?

**For competitive analysis:**
Run the market through lenses 1 (moat), 4 (incumbent failure), 18 (competitive response). Where's the structural gap?

**For monetization:**
Run the product through lenses 10 (edge-case), 12 (pricing), 6 (lock-in). What's worth paying for?

**For risk assessment:**
Run the plan through lenses 7 (liability), 8 (regulation), 19 (second-order). What could go wrong?

**For go-to-market:**
Run the launch through lenses 15 (experiments), 16 (partnerships), 17 (narrative). Is the story clear?

**For scaling:**
Run the system through lenses 13 (ops), 14 (market map), 19 (second-order). What breaks at 10×?

---

## Lens Combinations

Some lenses work in tension. Running both surfaces tradeoffs:

| Tension | Lenses | What it reveals |
|---------|--------|-----------------|
| Growth vs. Retention | 3 (distribution) vs. 6 (lock-in) | Are we optimizing for new users or keeping existing ones? |
| Focus vs. Expansion | 11 (persona purist) vs. 14 (market map) | Are we too narrow or too scattered? |
| Speed vs. Defensibility | 15 (experiments) vs. 1 (moat) | Are we learning fast enough or building deep enough? |
| Free vs. Paid | 3 (distribution) vs. 12 (pricing) | What should be free for growth vs. paid for revenue? |
| Automation vs. Control | 9 (time collapse) vs. 19 (second-order) | What should we automate vs. keep human-supervised? |

---

## Running a Lens Session

1. **Pick the lens** — Choose based on the question you're stuck on
2. **State the subject** — What feature, decision, or direction are you examining?
3. **Answer every question** — Don't skip. The uncomfortable ones matter most.
4. **Note the red flags** — Did any apply?
5. **Capture the insight** — What did the lens reveal that wasn't obvious before?

The lens doesn't decide. You decide. The lens makes sure you've thought about what matters.
